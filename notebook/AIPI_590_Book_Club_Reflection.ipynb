{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQRb/0wFJjSrpn6phebWsm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zsx711/AIPI-590/blob/main/notebook/AIPI_590_Book_Club_Reflection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AIPI 590 - XAI | Book Club Reflection\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S_vIToYplic9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shunxin Zhang"
      ],
      "metadata": {
        "id": "C6VeQ66fiEiX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notebook:https://colab.research.google.com/github/zsx711/AIPI-590/blob/main/notebook/AIPI_590_Book_Club_Reflection.ipynb [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zsx711/AIPI-590/blob/main/notebook/AIPI_590_Book_Club_Reflection.ipynb)"
      ],
      "metadata": {
        "id": "ZY1auyW7iX1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflection on The Alignment Problem by Brian Christian"
      ],
      "metadata": {
        "id": "pG9ciblGillG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading Brian Christian's *The Alignment Problem* and taking part in our book club discussions this semester has been a really inspiring experience. The book goes deeply into the development of AI systems, their flaws, and solutions. I now have a better sense of how AI affects society and why alignment—ensuring that AI adheres to human values—is such a crucial problem due to our discussions.\n",
        "\n",
        "The chapter on using AI to forecast crime was one that truly caught my attention. Although it sounds like something from a science fiction film, predictive policing is already in use today. Christian points out how risk assessment algorithms like COMPAS have come under fire for being discriminatory against Black people. This is closely related to the topic we covered in class regarding how biases in the data that AI systems are trained on are passed down to them. Despite its apparent neutrality, AI has the potential to exacerbate already-existing social injustices. We gave the example of how law enforcement uses face recognition technology and how it disproportionately misidentifies individuals of color throughout the course of our discussion. It got me to thinking about how critical it is to consider not only the accuracy of these systems but also the people they are most affecting.\n",
        "\n",
        "The bias of the initial cameras toward lighter skin tones was another notable example from the book. This was brought up at our first book club meeting, and it was a particularly memorable moment for me. Darker skin tones are more difficult to accurately capture with cameras that were made to optimize for lighter skin. I didn't think this was a huge concern at first, but Christian makes a bigger point about how technology may exclude entire groups of people when it is created without considering diversity. I became aware of how bias in technology is nothing new as a result of this case. It has existed since the beginning and continues to be a problem in AI today. For example, it has been discovered that even contemporary AI systems, such as automated employment tools, discriminate on the basis of race and gender. I became aware of the significance of including a variety of viewpoints in the design process as a result of this.\n",
        "\n",
        "We also talked about deepfake technology in a very interesting way. According to the book, sophisticated AI can now produce phony audio and video that are nearly impossible to distinguish from authentic ones. We recently talked about the Zoom financial scams in Hong Kong, where employees were tricked into sending money by using deepfake technology to pose as CEOs. Because it demonstrated how AI may be used as a weapon for negative purposes, this truly resonated with me. Christian illustrates how deepfakes have the potential to upend entire democracies using the example of phony political films. Our conversation got me thinking about how awareness and education are just as crucial as the technology itself. People will be susceptible to various forms of manipulation if they are unable to recognize deepfakes.\n",
        "\n",
        "The tale of AlphaGo, the AI that defeated the world champion at Go, was another aspect of the book that attracted me. Christian describes how innovation, not just skill, was the key to AlphaGo's win. Even human scientists were unable to comprehend the sudden movements it made. This relates to the class discussion on explainability in AI. If we don't grasp how AI systems operate, how can we trust them?\n",
        "\n",
        "I now view AI differently after reading The Alignment Problem. Prior to this, I primarily thought AI was cool and futuristic. I now see how intricate and disorganized it truly is. I became more conscious of the moral obligations associated with creating these systems after reading the book. Making things work for everyone is more important than just making them work. One thing I've learned is how crucial it is to consider who stands to gain and who could lose from artificial intelligence. These systems can have a significant impact on people's lives, whether they be hiring algorithms, deepfakes, or biased crime prediction tools. This insight has motivated me to learn more about technology ethics and how I may help create inclusive and equitable systems."
      ],
      "metadata": {
        "id": "_TdY0MgGingT"
      }
    }
  ]
}